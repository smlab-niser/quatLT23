{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/home/aritra/project/quartLT23/data/tiny_imagenet/tiny-imagenet-200\"\n",
    "file = open(f\"{base_dir}/wnids.txt\", \"r\")\n",
    "classes = file.readlines()\n",
    "# print((classes))\n",
    "file.close()\n",
    "\n",
    "classinfo = {}\n",
    "for i in range(200):\n",
    "    classinfo[i] = classes[i][:-1]\n",
    "print(classinfo)  \n",
    "\n",
    "train_dir = base_dir+\"/train\"\n",
    "test_dir = base_dir+\"/test\"\n",
    "val_dir = base_dir+\"/val\"  \n",
    "\n",
    "del classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST CELL\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correcting grayscales\n",
    "\n",
    "badcount = 0\n",
    "for i in range(200):\n",
    "    for j in trange(500):\n",
    "        img = plt.imread(f\"{train_dir}/{classinfo[i]}/images/{classinfo[i]}_{j}.JPEG\")\n",
    "        if img.shape == (64,64):\n",
    "            badcount += 1\n",
    "            plt.imsave(f\"{train_dir}/{classinfo[i]}/images/{classinfo[i]}_{j}.JPEG\",np.append(img,np.append(img,img)).reshape((3, 64, 64)).transpose(1, 2, 0))\n",
    "            \n",
    "print(f\"grayscale:{badcount}\")\n",
    "\n",
    "# grayscale_train: 1821\n",
    "# grayscale_val: 168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    train_class = np.array([np.insert(np.array(plt.imread(f\"{train_dir}/{classinfo[i]}/images/{classinfo[i]}_0.JPEG\")).flatten(),0,i)])\n",
    "    for j in trange(1,500):\n",
    "        # print(f\"{i}th class, {j}th image)\n",
    "        train_class = np.append(train_class,[np.insert(np.array(plt.imread(f\"{train_dir}/{classinfo[i]}/images/{classinfo[i]}_{j}.JPEG\")).flatten(),0,i)],axis=0)\n",
    "    if i == 0:\n",
    "        train = np.copy(train_class)\n",
    "        continue\n",
    "    train = np.append(train,train_class,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train)\n",
    "\n",
    "np.random.seed(69)\n",
    "np.random.shuffle(train)\n",
    "print(train)\n",
    "np.save(\"train_shuffled.npy\",train)\n",
    "\n",
    "del train\n",
    "# grayscale:1821"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORganizing test labels\n",
    "file = open(f\"{val_dir}/val_annotations.txt\", \"r\")\n",
    "labels = file.readlines()\n",
    "# print((classes))\n",
    "file.close()\n",
    "\n",
    "labels2 = {}\n",
    "for i in range(10000):\n",
    "    x,y = labels[i].split()[:2]\n",
    "    for j in range(200):\n",
    "        if classinfo[j] == y:y = j\n",
    "    labels2[x] = y\n",
    "print(labels2)  \n",
    "# print(classinfo[163])\n",
    " \n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([])\n",
    "img = np.array(plt.imread(f\"{val_dir}/images/val_0.JPEG\")).flatten()\n",
    "img = np.insert(img,0,labels2[f'val_0.JPEG'])\n",
    "test = np.array([img])\n",
    "# print(test)\n",
    "for j in tqdm(range(10000)):\n",
    "    if j == 0: continue\n",
    "    # print(f\"{j}th image\")\n",
    "    test = np.append(test,[np.insert(np.array(plt.imread(f\"{val_dir}/images/val_{j}.JPEG\")).flatten(),0,labels2[f'val_{j}.JPEG'])],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(69)\n",
    "# np.random.shuffle(test)\n",
    "# print(test)\n",
    "np.save(\"test.npy\",test)\n",
    "\n",
    "del test\n",
    "# grayscale:168"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tiny-imagenet-200"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9811a1b4b320249fa0a982ba121194d0140ee07c8f10e9998a7dff6636dbb876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
