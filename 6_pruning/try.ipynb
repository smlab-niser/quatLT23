{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from utils import train\n",
    "from data_loaders.imagenet import Train, Val\n",
    "from models.resnet_real import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "from models.resnet_quat import ResNet18_quat, ResNet34_quat, ResNet50_quat, ResNet101_quat, ResNet152_quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    \"batch_size\": 256,\n",
    "    \"num_epochs\": 20,\n",
    "    \"model\": \"ResNet34_quat\",\n",
    "    \"dataset\": \"imagenet64\",\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"gpu\": 0,\n",
    "}\n",
    "\n",
    "CPU = torch.device('cpu')\n",
    "GPU = torch.device(f'cuda:{hparams[\"gpu\"]}')\n",
    "\n",
    "log = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_name = f\"4-{hparams['model']}_{hparams['dataset']}_B={hparams['batch_size']}_O={hparams['optimizer']}_ll={hparams['learning_rate']}\"\n",
    "# save_name = f\"trial34_full\"\n",
    "\n",
    "model_name = hparams[\"model\"]\n",
    "if model_name == \"ResNet18\": model = ResNet18(4)\n",
    "elif model_name == \"ResNet34\": model = ResNet34(4)\n",
    "elif model_name == \"ResNet50\": model = ResNet50(4)\n",
    "elif model_name == \"ResNet101\": model = ResNet101(4)\n",
    "elif model_name == \"ResNet152\": model = ResNet152(4)\n",
    "elif model_name == \"ResNet18_quat\": model = ResNet18_quat(4)\n",
    "elif model_name == \"ResNet34_quat\": model = ResNet34_quat(4)\n",
    "elif model_name == \"ResNet50_quat\": model = ResNet50_quat(4)\n",
    "elif model_name == \"ResNet101_quat\": model = ResNet101_quat(4)\n",
    "elif model_name == \"ResNet152_quat\": model = ResNet152_quat(4)\n",
    "else: raise ValueError(\"Invalid model name\")\n",
    "\n",
    "# model = torch.load(\"saved_models/4-new-ResNet34_imagenet64_B=64_O=adam_ll=0.001_E=10.pth\")\n",
    "\n",
    "model.to(GPU)\n",
    "# optimiser = torch.optim.SGD(model.parameters(), lr=hparams[\"learning_rate\"])\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "if log:\n",
    "    import wandb\n",
    "    wandb.init(project=\"QuatLT23\", name=save_name, config=hparams)\n",
    "    wandb.watch(model)\n",
    "\n",
    "print(\"Loading data...\")\n",
    "training_generator = torch.utils.data.DataLoader(Train(), shuffle=False, batch_size=hparams[\"batch_size\"], num_workers=4)\n",
    "validation_generator = torch.utils.data.DataLoader(Val(), shuffle=False, batch_size=hparams[\"batch_size\"], num_workers=4)\n",
    "# m = len(training_set)\n",
    "\n",
    "batch_size = hparams[\"batch_size\"]\n",
    "num_epochs = hparams[\"num_epochs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, num_epochs, training_generator, validation_generator, optimiser, loss_fn, save = save_name, GPU=GPU, log=log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
