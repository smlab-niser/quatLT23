{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from time import time\n",
    "# from resnet_real import ResNet18\n",
    "# from resnet_quat import ResNet18_quat\n",
    "from tqdm import tqdm, trange\n",
    "from htorch import layers as quatnn\n",
    "from torch.nn import init\n",
    "from htorch.quaternion import QuaternionTensor as Q\n",
    "\n",
    "GPU = torch.device('cuda:0')\n",
    "bn_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QBatchNorm2d_0(nn.Module):\n",
    "    \"\"\"\n",
    "    Quaternion batch normalization 2d\n",
    "    please check whitendxd in cplx module at https://github.com/ivannz\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 affine=True,\n",
    "                 training=True,\n",
    "                 eps=1e-5,\n",
    "                 momentum=0.9,\n",
    "                 track_running_stats=True):\n",
    "        \"\"\"\n",
    "        @type in_channels: int\n",
    "        @type affine: bool\n",
    "        @type training: bool\n",
    "        @type eps: float\n",
    "        @type momentum: float\n",
    "        @type track_running_stats: bool\n",
    "        \"\"\"\n",
    "        super(QBatchNorm2d_0, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.affine = affine\n",
    "        self.training = training\n",
    "        self.track_running_stats = track_running_stats\n",
    "        self.register_buffer('eye', torch.diag(torch.cat([torch.Tensor([eps])] * 4)).unsqueeze(0))\n",
    "\n",
    "        if self.affine:\n",
    "            self.weight = torch.nn.Parameter(torch.zeros(4, 4, in_channels))\n",
    "            self.bias = torch.nn.Parameter(torch.zeros(4, in_channels))\n",
    "        else:\n",
    "            self.register_parameter('weight', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        if self.track_running_stats:\n",
    "            self.register_buffer('running_mean', torch.zeros(4, in_channels))\n",
    "            self.register_buffer('running_cov', torch.zeros(in_channels, 4, 4))\n",
    "        else:\n",
    "            self.register_parameter('running_mean', None)\n",
    "            self.register_parameter('running_cov', None)\n",
    "\n",
    "        self.momentum = momentum\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_running_stats(self):\n",
    "        if self.track_running_stats:\n",
    "            self.running_mean.zero_()\n",
    "            self.running_cov.zero_()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.reset_running_stats()\n",
    "        if self.affine:\n",
    "            init.constant_(self.weight[0, 0], 0.5)\n",
    "            init.constant_(self.weight[1, 1], 0.5)\n",
    "            init.constant_(self.weight[2, 2], 0.5)\n",
    "            init.constant_(self.weight[3, 3], 0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"\\t\\t\\tBN: {self.in_channels = }\")\n",
    "        x = torch.stack(torch.chunk(x, 4, 1), 1).permute(1, 0, 2, 3, 4)\n",
    "        axes, d = (1, *range(3, x.dim())), x.shape[0]\n",
    "        shape = 1, x.shape[2], *([1] * (x.dim() - 3))\n",
    "\n",
    "        if self.training:\n",
    "            mean = x.mean(dim=axes)\n",
    "            if self.running_mean is not None:\n",
    "                with torch.no_grad():\n",
    "                    self.running_mean = self.momentum * self.running_mean + \\\n",
    "                                        (1.0 - self.momentum) * mean\n",
    "        else:\n",
    "            mean = self.running_mean\n",
    "\n",
    "        x = x - mean.reshape(d, *shape)\n",
    "\n",
    "        if self.training:\n",
    "            perm = x.permute(2, 0, *axes).flatten(2, -1)\n",
    "            cov = torch.matmul(perm, perm.transpose(-1, -2)) / perm.shape[-1]\n",
    "\n",
    "            if self.running_cov is not None:\n",
    "                with torch.no_grad():\n",
    "                    self.running_cov = self.momentum * self.running_cov + \\\n",
    "                                       (1.0 - self.momentum) * cov\n",
    "\n",
    "        else:\n",
    "            cov = self.running_cov\n",
    "\n",
    "        ell = torch.cholesky(cov + self.eye, upper=True)\n",
    "        soln = torch.triangular_solve(\n",
    "            x.unsqueeze(-1).permute(*range(1, x.dim()), 0, -1),\n",
    "            ell.reshape(*shape, d, d)\n",
    "        )\n",
    "\n",
    "        wht = soln.solution.squeeze(-1)\n",
    "        z = torch.stack(torch.unbind(wht, dim=-1), dim=0)\n",
    "\n",
    "        if self.affine:\n",
    "            weight = self.weight.view(4, 4, *shape)\n",
    "            scaled = torch.stack([\n",
    "                z[0] * weight[0, 0] + z[1] * weight[0, 1] + z[2] * weight[0, 2] + z[3] * weight[0, 3],\n",
    "                z[0] * weight[1, 0] + z[1] * weight[1, 1] + z[2] * weight[1, 2] + z[3] * weight[1, 3],\n",
    "                z[0] * weight[2, 0] + z[1] * weight[2, 1] + z[2] * weight[2, 2] + z[3] * weight[2, 3],\n",
    "                z[0] * weight[3, 0] + z[1] * weight[3, 1] + z[2] * weight[3, 2] + z[3] * weight[3, 3],\n",
    "            ], dim=0)\n",
    "            z = scaled + self.bias.reshape(4, *shape)\n",
    "\n",
    "        z = torch.cat(torch.chunk(z, 4, 0), 2).squeeze()\n",
    "        \n",
    "        if z.dim() == 2:\n",
    "            z = z.reshape(z.shape[0], z.shape[1], 1, 1)\n",
    "\n",
    "        # print(f\"shape before returning: {z.shape = }\")\n",
    "\n",
    "        return Q(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_real = nn.BatchNorm2d(8).to(GPU)\n",
    "model_quat = QBatchNorm2d_0(2).to(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchx = torch.randn(256, 8, 224, 224).to(GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2453061/3557134005.py:90: UserWarning: torch.cholesky is deprecated in favor of torch.linalg.cholesky and will be removed in a future PyTorch release.\n",
      "L = torch.cholesky(A)\n",
      "should be replaced with\n",
      "L = torch.linalg.cholesky(A)\n",
      "and\n",
      "U = torch.cholesky(A, upper=True)\n",
      "should be replaced with\n",
      "U = torch.linalg.cholesky(A).mH().\n",
      "This transform will produce equivalent results for all valid (symmetric positive definite) inputs. (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:1691.)\n",
      "  ell = torch.cholesky(cov + self.eye, upper=True)\n",
      "/tmp/ipykernel_2453061/3557134005.py:91: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at ../aten/src/ATen/native/BatchLinearAlgebra.cpp:2191.)\n",
      "  soln = torch.triangular_solve(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 8, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quat(batchx).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 417.67it/s]\n",
      "100%|██████████| 1000/1000 [00:38<00:00, 25.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real: 23.94432520866394\n",
      "Quat: 386.65738582611084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "repeat = 10000\n",
    "e = 10\n",
    "\n",
    "start = time()\n",
    "for i in trange(repeat):\n",
    "    output = model_real(batchx)\n",
    "end = time()\n",
    "real_time = (end - start)\n",
    "\n",
    "start = time()\n",
    "for i in trange(repeat//e):\n",
    "    output = model_quat(batchx)\n",
    "end = time()\n",
    "quat_time = (end - start)*e\n",
    "\n",
    "print(f\"Real: {real_time}\")\n",
    "print(f\"Quat: {quat_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quat is about 16.1x slower than Real\n"
     ]
    }
   ],
   "source": [
    "print(f\"Quat is about {quat_time/real_time:.1f}x slower than Real\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight', 'bias', 'running_mean', 'running_var', 'num_batches_tracked'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_real.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight', 'bias', 'eye', 'running_mean', 'running_cov'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quat.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([4, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "print(model_real.weight.shape)\n",
    "print(model_quat.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0.5000, 0.5000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.0000, 0.0000]],\n",
       "\n",
       "        [[0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.5000, 0.5000]]], device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_quat.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(5,2)\n",
    "g = np.random.rand(1,2)\n",
    "b = np.random.rand(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19776855, 0.48728672]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03381753, 0.20481149],\n",
       "       [0.5940217 , 0.2110181 ],\n",
       "       [0.20750374, 0.19137958],\n",
       "       [0.34746205, 0.19015002],\n",
       "       [0.01904878, 0.03207484]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x*g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23158609, 0.69209821],\n",
       "       [0.79179025, 0.69830482],\n",
       "       [0.40527229, 0.6786663 ],\n",
       "       [0.5452306 , 0.67743674],\n",
       "       [0.21681733, 0.51936156]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x*g) + b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
