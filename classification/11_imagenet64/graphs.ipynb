{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from utils.training import train_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import numpy as np\n",
    "from utils.pruning import get_prune_percentage, prune_model, number_of_parameters\n",
    "from models.resnet_real import ResNet101, ResNet152\n",
    "from models.resnet_quat import ResNet101_quat, ResNet152_quat\n",
    "from oth import *\n",
    "import json\n",
    "import torch.multiprocessing as mp\n",
    "from data_loaders.imagenet import Train, Val\n",
    "\n",
    "GPU = torch.device(\"cuda:0\")\n",
    "base_dir = \"saved_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"RN18_real\", \"RN18_quat\", \"RN34_real\", \"RN34_quat\", \"RN50_real\", \"RN50_quat\", \"RN101_real\", \"RN101_quat\", \"RN152_real\", \"RN152_quat\"]\n",
    "for name in models:\n",
    "    a = torch.load(f'saved_models/{name}_prune/{name}_unpruned.pt')\n",
    "    print(f\"{name}:\\t{number_of_parameters(a)/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule(x):\n",
    "    a = x[:-3].split(\"_\")[-1]\n",
    "    try: return int(a)\n",
    "    except: return 0\n",
    "\n",
    "def proc(num, n = 2):\n",
    "    if isinstance(num, int): return num\n",
    "    else:\n",
    "        if int(num) == num: return int(num)\n",
    "        else: return round(num, n)\n",
    "\n",
    "model_groups = {\n",
    "    18:  [\"RN18_real\", \"RN18_quat\"],\n",
    "    34:  [\"RN34_real\", \"RN34_quat\"],\n",
    "    50:  [\"RN50_real\", \"RN50_quat\"],\n",
    "    101: [\"RN101_real\", \"RN101_quat\"],\n",
    "    152: [\"RN152_real\", \"RN152_quat\"]\n",
    "}\n",
    "unif = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = torch.utils.data.DataLoader(Val(), batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "models = model_groups[18]\n",
    "if load:\n",
    "    with open(\"saved_models/RN18.json\") as f:\n",
    "        models = json.load(f)\n",
    "else:\n",
    "    model_paths = {}\n",
    "\n",
    "    # finding the saved models\n",
    "    for model in models:\n",
    "        path = f\"{base_dir}/{model}_prune\"\n",
    "        model_paths[model] = {k:{\"accuracy\":None, \"prune_perc\": None} for k in sorted(map(lambda x: f\"{path}/{x}\", listdir(path)), key = rule)}\n",
    "    models =  model_paths\n",
    "\n",
    "    # evaluating the saved models\n",
    "    for model_type in models:\n",
    "        for model_path in tqdm(models[model_type], desc = model_type, unit = \"model\"):\n",
    "            model = torch.load(model_path).to(GPU)\n",
    "            models[model_type][model_path][\"prune_perc\"] = get_prune_percentage(model)\n",
    "            models[model_type][model_path][\"accuracy\"] = train_accuracy(model, validation_generator, GPU)\n",
    "\n",
    "    with open(\"saved_models/RN18.json\", \"w\") as f:\n",
    "        json.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RN18_real:  11.68M\n",
    "# RN18_quat:  2.93M\n",
    "\n",
    "real_prune_percs = []\n",
    "real_test_accs = []\n",
    "real_num_params = []\n",
    "for m in models[\"RN18_real\"].values():\n",
    "    real_prune_percs.append(m[\"prune_perc\"]*100)\n",
    "    real_num_params.append(m[\"prune_perc\"]*11.68)\n",
    "    real_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "quat_prune_percs = []\n",
    "quat_test_accs = []\n",
    "quat_num_params = []\n",
    "for m in models[\"RN18_quat\"].values():\n",
    "    quat_prune_percs.append(m[\"prune_perc\"]*25)\n",
    "    quat_num_params.append(m[\"prune_perc\"]*2.93)\n",
    "    quat_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "unif[\"R18_acc\"] = real_test_accs\n",
    "unif[\"R18_prune\"] = real_prune_percs\n",
    "unif[\"R18_params\"] = real_num_params\n",
    "unif[\"Q18_acc\"] = quat_test_accs\n",
    "unif[\"Q18_prune\"] = quat_prune_percs\n",
    "unif[\"Q18_params\"] = quat_num_params\n",
    "\n",
    "plt.plot(real_prune_percs, real_test_accs, linestyle=\"-\", marker=\".\", color=\"tab:blue\", label=\"RN18 Real test acc\")\n",
    "plt.plot(quat_prune_percs, quat_test_accs, linestyle=\":\", marker=\".\", color=\"tab:blue\", label=\"RN18 Quat test acc\")\n",
    "\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks = [100*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks, [f\"{proc(t)}%\" for t in ticks], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/RN18.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "models = model_groups[34]\n",
    "if load:\n",
    "    with open(\"saved_models/RN34.json\") as f:\n",
    "        models = json.load(f)\n",
    "else:\n",
    "    model_paths = {}\n",
    "\n",
    "    # finding the saved models\n",
    "    for model in models:\n",
    "        path = f\"{base_dir}/{model}_prune\"\n",
    "        model_paths[model] = {k:{\"accuracy\":None, \"prune_perc\": None} for k in sorted(map(lambda x: f\"{path}/{x}\", listdir(path)), key = rule)}\n",
    "    models =  model_paths\n",
    "\n",
    "    # evaluating the saved models\n",
    "    for model_type in models:\n",
    "        for model_path in tqdm(models[model_type], desc = model_type, unit = \"model\"):\n",
    "            model = torch.load(model_path).to(GPU)\n",
    "            models[model_type][model_path][\"prune_perc\"] = get_prune_percentage(model)\n",
    "            models[model_type][model_path][\"accuracy\"] = train_accuracy(model, validation_generator, GPU)\n",
    "\n",
    "    with open(\"saved_models/RN34.json\", \"w\") as f:\n",
    "        json.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RN34_real:  21.79M\n",
    "# RN34_quat:  5.46M\n",
    "\n",
    "real_prune_percs = []\n",
    "real_num_params = []\n",
    "real_test_accs = []\n",
    "for m in models[\"RN34_real\"].values():\n",
    "    real_prune_percs.append(m[\"prune_perc\"]*100)\n",
    "    real_num_params.append(m[\"prune_perc\"]*21.79)\n",
    "    real_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "quat_prune_percs = []\n",
    "quat_test_accs = []\n",
    "quat_num_params = []\n",
    "for m in models[\"RN34_quat\"].values():\n",
    "    quat_prune_percs.append(m[\"prune_perc\"]*25)\n",
    "    quat_num_params.append(m[\"prune_perc\"]*5.46)\n",
    "    quat_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "unif[\"R34_acc\"] = real_test_accs\n",
    "unif[\"R34_prune\"] = real_prune_percs\n",
    "unif[\"R34_params\"] = real_num_params\n",
    "unif[\"Q34_acc\"] = quat_test_accs\n",
    "unif[\"Q34_prune\"] = quat_prune_percs\n",
    "unif[\"Q34_params\"] = quat_num_params\n",
    "\n",
    "plt.plot(real_prune_percs, real_test_accs, linestyle=\"-\", marker=\".\", color=\"tab:orange\", label=\"RN34 Real test acc\")\n",
    "plt.plot(quat_prune_percs, quat_test_accs, linestyle=\":\", marker=\".\", color=\"tab:orange\", label=\"RN34 Quat test acc\")\n",
    "\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks = [100*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks, [f\"{proc(t)}%\" for t in ticks], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/RN34.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "models = model_groups[50]\n",
    "\n",
    "if load:\n",
    "    with open(\"saved_models/RN50.json\") as f:\n",
    "        models = json.load(f)\n",
    "else:\n",
    "    model_paths = {}\n",
    "\n",
    "    # finding the saved models\n",
    "    for model in models:\n",
    "        path = f\"{base_dir}/{model}_prune\"\n",
    "        model_paths[model] = {k:{\"accuracy\":None, \"prune_perc\": None} for k in sorted(map(lambda x: f\"{path}/{x}\", listdir(path)), key = rule)}\n",
    "    models =  model_paths\n",
    "\n",
    "    # evaluating the saved models\n",
    "    for model_type in models:\n",
    "        for model_path in tqdm(models[model_type], desc = model_type, unit = \"model\"):\n",
    "            model = torch.load(model_path).to(GPU)\n",
    "            models[model_type][model_path][\"prune_perc\"] = get_prune_percentage(model)\n",
    "            models[model_type][model_path][\"accuracy\"] = train_accuracy(model, validation_generator, GPU)\n",
    "\n",
    "    # with open(\"saved_models/RN50.json\", \"w\") as f:\n",
    "    #     json.dump(models, f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_prune_percs = []\n",
    "real_test_accs = []\n",
    "real_num_params = []\n",
    "for m in models[\"RN50_real\"].values():\n",
    "    real_prune_percs.append(m[\"prune_perc\"]*100)\n",
    "    real_num_params.append(m[\"prune_perc\"]*25.55)\n",
    "    real_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "quat_prune_percs = []\n",
    "quat_test_accs = []\n",
    "quat_num_params = []\n",
    "for m in models[\"RN50_quat\"].values():\n",
    "    quat_prune_percs.append(m[\"prune_perc\"]*25)\n",
    "    quat_num_params.append(m[\"prune_perc\"]*6.43)\n",
    "    quat_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "unif[\"R50_acc\"] = real_test_accs\n",
    "unif[\"R50_prune\"] = real_prune_percs\n",
    "unif[\"R50_params\"] = real_num_params\n",
    "unif[\"Q50_acc\"] = quat_test_accs\n",
    "unif[\"Q50_prune\"] = quat_prune_percs\n",
    "unif[\"Q50_params\"] = quat_num_params\n",
    "\n",
    "plt.plot(real_prune_percs, real_test_accs, linestyle=\"-\", marker=\".\", color=\"tab:green\", label=\"RN50 Real test acc\")\n",
    "plt.plot(quat_prune_percs, quat_test_accs, linestyle=\":\", marker=\".\", color=\"tab:green\", label=\"RN50 Quat test acc\")\n",
    "\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks = [100*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks, [f\"{proc(t)}%\" for t in ticks], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/RN50.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = False\n",
    "models = model_groups[101]\n",
    "# /home/aritra/project/quatLT23/precious_saved_models\n",
    "if load:\n",
    "    with open(\"saved_models/RN101.json\") as f:\n",
    "        models = json.load(f)\n",
    "else:\n",
    "    model_paths = {}\n",
    "\n",
    "    # finding the saved models\n",
    "    for model in models:\n",
    "        path = f\"saved_models/{model}_prune\"\n",
    "        model_paths[model] = {k:{\"accuracy\":None, \"prune_perc\": None} for k in sorted(map(lambda x: f\"{path}/{x}\", listdir(path)), key = rule)}\n",
    "    models =  model_paths\n",
    "\n",
    "    # evaluating the saved models\n",
    "    for model_type in models:\n",
    "        for model_path in tqdm(models[model_type], desc = model_type, unit = \"model\"):\n",
    "            model = torch.load(model_path).to(GPU)\n",
    "            models[model_type][model_path][\"prune_perc\"] = get_prune_percentage(model)\n",
    "            models[model_type][model_path][\"accuracy\"] = train_accuracy(model, validation_generator, GPU)\n",
    "\n",
    "    with open(\"saved_models/RN101.json\", \"w\") as f:\n",
    "        json.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RN101_real: 44.54M\n",
    "# RN101_quat: 11.22M\n",
    "\n",
    "real_prune_percs = []\n",
    "real_test_accs = []\n",
    "real_num_params = []\n",
    "for m in models[\"RN101_real\"].values():\n",
    "    real_prune_percs.append(m[\"prune_perc\"]*100)\n",
    "    real_num_params.append(m[\"prune_perc\"]*44.54)\n",
    "    real_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "quat_prune_percs = []\n",
    "quat_test_accs = []\n",
    "quat_num_params = []\n",
    "for m in models[\"RN101_quat\"].values():\n",
    "    quat_prune_percs.append(m[\"prune_perc\"]*25)\n",
    "    quat_num_params.append(m[\"prune_perc\"]*11.22)\n",
    "    quat_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "unif[\"R101_acc\"] = real_test_accs\n",
    "unif[\"R101_prune\"] = real_prune_percs\n",
    "unif[\"R101_params\"] = real_num_params\n",
    "unif[\"Q101_acc\"] = quat_test_accs\n",
    "unif[\"Q101_prune\"] = quat_prune_percs\n",
    "unif[\"Q101_params\"] = quat_num_params\n",
    "\n",
    "plt.plot(real_prune_percs[:-1], real_test_accs[:-1], linestyle=\"-\", marker=\".\", color=\"tab:red\", label=\"RN101 Real test acc\")\n",
    "plt.plot(quat_prune_percs[:-1], quat_test_accs[:-1], linestyle=\":\", marker=\".\", color=\"tab:red\", label=\"RN101 Quat test acc\")\n",
    "\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks = [100*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks, [f\"{proc(t)}%\" for t in ticks], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/RN152.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet 152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = True\n",
    "models = model_groups[152]\n",
    "# /home/aritra/project/quatLT23/precious_saved_models\n",
    "if load:\n",
    "    with open(\"saved_models/RN152.json\") as f:\n",
    "        models = json.load(f)\n",
    "else:\n",
    "    model_paths = {}\n",
    "\n",
    "    # finding the saved models\n",
    "    for model in models:\n",
    "        path = f\"saved_models/{model}_prune\"\n",
    "        model_paths[model] = {k:{\"accuracy\":None, \"prune_perc\": None} for k in sorted(map(lambda x: f\"{path}/{x}\", listdir(path)), key = rule)}\n",
    "    models =  model_paths\n",
    "\n",
    "    # evaluating the saved models\n",
    "    for model_type in models:\n",
    "        for model_path in tqdm(models[model_type], desc = model_type, unit = \"model\"):\n",
    "            model = torch.load(model_path).to(GPU)\n",
    "            models[model_type][model_path][\"prune_perc\"] = get_prune_percentage(model)\n",
    "            models[model_type][model_path][\"accuracy\"] = train_accuracy(model, validation_generator, GPU)\n",
    "\n",
    "    with open(\"saved_models/RN152.json\", \"w\") as f:\n",
    "        json.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RN152_real:  60.19M\n",
    "# RN152_quat:  15.16M\n",
    "\n",
    "real_prune_percs = []\n",
    "real_test_accs = []\n",
    "real_num_params = []\n",
    "for m in models[\"RN152_real\"].values():\n",
    "    real_prune_percs.append(m[\"prune_perc\"]*100)\n",
    "    real_num_params.append(m[\"prune_perc\"]*60.19)\n",
    "    real_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "quat_prune_percs = []\n",
    "quat_test_accs = []\n",
    "quat_num_params = []\n",
    "for m in models[\"RN152_quat\"].values():\n",
    "    quat_prune_percs.append(m[\"prune_perc\"]*25)\n",
    "    quat_num_params.append(m[\"prune_perc\"]*15.16)\n",
    "    quat_test_accs.append(m[\"accuracy\"])\n",
    "\n",
    "unif[\"R152_acc\"] = real_test_accs\n",
    "unif[\"R152_prune\"] = real_prune_percs\n",
    "unif[\"R152_params\"] = real_num_params\n",
    "unif[\"Q152_acc\"] = quat_test_accs\n",
    "unif[\"Q152_prune\"] = quat_prune_percs\n",
    "unif[\"Q152_params\"] = quat_num_params\n",
    "\n",
    "plt.plot(real_prune_percs[:-1], real_test_accs[:-1], linestyle=\"-\", marker=\".\", color=\"tab:purple\", label=\"RN152 Real test acc\")\n",
    "plt.plot(quat_prune_percs[:-1], quat_test_accs[:-1], linestyle=\":\", marker=\".\", color=\"tab:purple\", label=\"RN152 Quat test acc\")\n",
    "\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks = [100*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks, [f\"{proc(t)}%\" for t in ticks], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/RN152.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(unif[\"R18_params\"], unif[\"R18_acc\"], linestyle=\"-\", marker=\".\", color=\"tab:blue\", label=\"RN18 Real test acc\")\n",
    "# plt.plot(unif[\"Q18_params\"], unif[\"Q18_acc\"], linestyle=\":\", marker=\".\", color=\"tab:blue\", label=\"RN18 Quat test acc\")\n",
    "plt.plot(unif[\"R34_params\"], unif[\"R34_acc\"], linestyle=\"-\", marker=\".\", color=\"tab:orange\", label=\"RN34 Real test acc\")\n",
    "# plt.plot(unif[\"Q34_params\"], unif[\"Q34_acc\"], linestyle=\":\", marker=\".\", color=\"tab:orange\", label=\"RN34 Quat test acc\")\n",
    "plt.plot(unif[\"R50_params\"][:-1], unif[\"R50_acc\"][:-1], linestyle=\"-\", marker=\".\", color=\"tab:green\", label=\"RN50 Real test acc\")\n",
    "# plt.plot(unif[\"Q50_params\"], unif[\"Q50_acc\"], linestyle=\":\", marker=\".\", color=\"tab:green\", label=\"RN50 Quat test acc\")\n",
    "plt.plot(unif[\"R101_params\"][:-1], unif[\"R101_acc\"][:-1], linestyle=\"-\", marker=\".\", color=\"tab:red\", label=\"RN101 Real test acc\")\n",
    "# plt.plot(unif[\"Q101_params\"][:-1], unif[\"Q101_acc\"][:-1], linestyle=\":\", marker=\".\", color=\"tab:purple\", label=\"RN101 Quat test acc\")\n",
    "plt.plot(unif[\"R152_params\"][:-1], unif[\"R152_acc\"][:-1], linestyle=\"-\", marker=\".\", color=\"tab:purple\", label=\"RN152 Real test acc\")\n",
    "# plt.plot(unif[\"Q152_params\"][:-1], unif[\"Q152_acc\"][:-1], linestyle=\":\", marker=\".\", color=\"tab:red\", label=\"RN152 Quat test acc\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of parameters\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "ticks2 = [60*0.5**i for i in range(14)]\n",
    "plt.xticks(ticks2, [f\"{proc(t, 3)}M\" for t in ticks2], rotation=30)\n",
    "plt.yticks(range(0, 70, 5))\n",
    "plt.ylim(0, 70)\n",
    "plt.grid()\n",
    "plt.savefig(\"saved_models/#params.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2301.04623.pdf\n",
    "# https://openreview.net/pdf?id=K398CuAKVKB"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
