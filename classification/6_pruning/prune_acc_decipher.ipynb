{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from utils.training import train\n",
    "from data_loaders.imagenet import Train, Val\n",
    "from models.resnet_real import ResNet18, ResNet34, ResNet50, ResNet101, ResNet152\n",
    "from models.resnet_quat import ResNet18_quat, ResNet34_quat, ResNet50_quat, ResNet101_quat, ResNet152_quat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  10%|â–ˆ         | 1/10 [00:04<00:40,  4.49s/batch]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 47.54 GiB total capacity; 45.84 GiB already allocated; 114.00 MiB free; 46.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m training_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(Train(\u001b[39m50000\u001b[39m), shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m], num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     32\u001b[0m validation_generator \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(Val(),      shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, batch_size\u001b[39m=\u001b[39mhparams[\u001b[39m\"\u001b[39m\u001b[39mbatch_size\u001b[39m\u001b[39m\"\u001b[39m], num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m acc_dict \u001b[39m=\u001b[39m all_acc_model(\n\u001b[1;32m     35\u001b[0m     model_path,\n\u001b[1;32m     36\u001b[0m     training_generator,\n\u001b[1;32m     37\u001b[0m     validation_generator,\n\u001b[1;32m     38\u001b[0m     GPU \u001b[39m=\u001b[39;49m torch\u001b[39m.\u001b[39;49mdevice(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda:0\u001b[39;49m\u001b[39m'\u001b[39;49m),\n\u001b[1;32m     39\u001b[0m     \u001b[39m# save = save_name,\u001b[39;49;00m\n\u001b[1;32m     40\u001b[0m     batches\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m \u001b[39mprint\u001b[39m(acc_dict)\n\u001b[1;32m     46\u001b[0m \u001b[39m# '''\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39m# 4:  (43.7890625, 62.9296875, 45.4296875, 70.0390625)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[39m# 10: (43.9453125, 63.0859375, 45.5078125, 70.9765625)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39m# 100:(43.828125, 63.359375, 44.4921875, 69.0234375)\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[39m# '''\u001b[39;00m\n",
      "File \u001b[0;32m~/project/quatLT23/utils/accuracy.py:46\u001b[0m, in \u001b[0;36mall_acc_model\u001b[0;34m(model_path, training_generator, validation_generator, GPU, batches)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m batch_x, batch_y \u001b[39min\u001b[39;00m tqdm(training_generator, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain\u001b[39m\u001b[39m\"\u001b[39m, unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m, total\u001b[39m=\u001b[39m\u001b[39mmin\u001b[39m(batches, \u001b[39mlen\u001b[39m(training_generator))):\n\u001b[1;32m     45\u001b[0m     batch_x, batch_y \u001b[39m=\u001b[39m batch_x\u001b[39m.\u001b[39mto(GPU), batch_y\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> 46\u001b[0m     output \u001b[39m=\u001b[39m model(batch_x)\n\u001b[1;32m     47\u001b[0m     acc1 \u001b[39m=\u001b[39m accuracy_score(batch_y\u001b[39m.\u001b[39mnumpy(), output\u001b[39m.\u001b[39margmax(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n\u001b[1;32m     48\u001b[0m     accs1\u001b[39m.\u001b[39mappend(acc1\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\n",
      "File \u001b[0;32m~/project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/quatLT23/models/resnet_real.py:100\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     98\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(x)\n\u001b[1;32m     99\u001b[0m \u001b[39m# print(f\"After bn1: {x.shape = }\")\u001b[39;00m\n\u001b[0;32m--> 100\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrelu(x)\n\u001b[1;32m    101\u001b[0m \u001b[39m# print(f\"After relu: {x.shape = }\")\u001b[39;00m\n\u001b[1;32m    102\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmaxpool(x)\n",
      "File \u001b[0;32m~/project/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/project/.venv/lib/python3.10/site-packages/torch/nn/modules/activation.py:103\u001b[0m, in \u001b[0;36mReLU.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 103\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m, inplace\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minplace)\n",
      "File \u001b[0;32m~/project/.venv/lib/python3.10/site-packages/torch/nn/functional.py:1457\u001b[0m, in \u001b[0;36mrelu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrelu_(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1456\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m     result \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrelu(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m   1458\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 784.00 MiB (GPU 0; 47.54 GiB total capacity; 45.84 GiB already allocated; 114.00 MiB free; 46.15 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# from data_loaders.ILSVRC import Train, Val\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from tqdm import tqdm, trange\n",
    "# from utils.training import train\n",
    "# from utils.accuracy import all_acc_prunemodels, top5acc_check, all_acc_model\n",
    "# hparams = {\n",
    "#     \"batch_size\": 256,\n",
    "#     \"num_epochs\": 15,\n",
    "#     \"model\": \"ResNet18\",\n",
    "#     \"dataset\": \"ILSVRC\",\n",
    "#     \"optimizer\": \"sgd\",\n",
    "#     \"learning_rate\": 0.1,\n",
    "#     \"gpu\": 0,\n",
    "#     \"pruning_percentages\": [100, 80, 64, 50, 32, 25, 20, 16, 13, 10, 8, 6, 4],\n",
    "#     \"batches\" : 1\n",
    "# }\n",
    "\n",
    "# model_name = \"RN18_real\"\n",
    "# models_folder = f\"/home/aritra/project/quatLT23/6_pruning/saved_models/{model_name}\"\n",
    "# save_name = f\"acc_{model_name}_prunes_trial2.txt\"\n",
    "# log = False #turn this on!\n",
    "\n",
    "# model_path = \"/home/aritra/project/quatLT23/6_pruning/saved_models/untitled/4-ResNet152_imagenet64_B=256_O=sgd_ll=0.1_E=35.pth\"\n",
    "\n",
    "# if log:\n",
    "#     import wandb\n",
    "#     wandb.init(project=\"QuatLT23\", name=\"LAST TRIAL DELETE\", config=hparams)\n",
    "# # ILSVRC_RN18_realprunes_trial2 accuracies\n",
    "# training_generator = torch.utils.data.DataLoader(Train(50000), shuffle=True, batch_size=hparams[\"batch_size\"], num_workers=4)\n",
    "# validation_generator = torch.utils.data.DataLoader(Val(),      shuffle=True, batch_size=hparams[\"batch_size\"], num_workers=4)\n",
    "\n",
    "# acc_dict = all_acc_model(\n",
    "#     model_path,\n",
    "#     training_generator,\n",
    "#     validation_generator,\n",
    "#     GPU = torch.device(f'cuda:0'),\n",
    "#     # save = save_name,\n",
    "#     batches=10\n",
    "# )\n",
    "\n",
    "# print(acc_dict)\n",
    "\n",
    "\n",
    "# '''\n",
    "# 4:  (43.7890625, 62.9296875, 45.4296875, 70.0390625)\n",
    "# 10: (43.9453125, 63.0859375, 45.5078125, 70.9765625)\n",
    "# 20: (44.1015625, 63.671875, 46.5234375, 71.875)\n",
    "# 50: (43.0078125, 61.40625, 44.9609375, 70.1953125)\n",
    "# 80: (43.203125, 63.3984375, 45.5078125, 70.9375)\n",
    "# 100:(43.828125, 63.359375, 44.4921875, 69.0234375)\n",
    "# '''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/4/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/4/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/4/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/4/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/4/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/4/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/4/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/4/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/4/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/4/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/4/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/4/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/4/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/4/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/4/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/6/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/6/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/6/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/6/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/6/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/6/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/6/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/6/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/6/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/6/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/6/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/6/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/6/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/6/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/6/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/8/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/8/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/8/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/8/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/8/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/8/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/8/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/8/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/8/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/8/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/8/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/8/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/8/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/8/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/8/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/10/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/10/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/10/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/10/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/10/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/10/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/10/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/10/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/10/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/10/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/10/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/10/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/10/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/10/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/10/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/13/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/13/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/13/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/13/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/13/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/13/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/13/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/13/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/13/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/13/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/13/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/13/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/13/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/13/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/13/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/16/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/16/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/16/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/16/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/16/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/16/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/16/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/16/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/16/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/16/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/16/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/16/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/16/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/16/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/16/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/20/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/20/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/20/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/20/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/20/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/20/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/20/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/20/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/20/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/20/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/20/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/20/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/20/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/20/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/20/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/25/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/25/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/25/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/25/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/25/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/25/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/25/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/25/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/25/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/25/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/25/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/25/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/25/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/25/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/25/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/32/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/32/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/32/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/32/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/32/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/32/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/32/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/32/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/32/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/32/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/32/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/32/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/32/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/32/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/32/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/50/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/50/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/50/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/50/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/50/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/50/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/50/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/50/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/50/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/50/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/50/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/50/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/50/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/50/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/50/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/64/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/64/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/64/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/64/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/64/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/64/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/64/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/64/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/64/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/64/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/64/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/64/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/64/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/64/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/64/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/80/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/80/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/80/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/80/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/80/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/80/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/80/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/80/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/80/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/80/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/80/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/80/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/80/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/80/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/80/15.pth': [41.40625, 60.9375, 44.140625, 68.75], '/100/1.pth': [10.546875, 26.953125, 19.921875, 39.0625], '/100/2.pth': [19.921875, 34.765625, 31.25, 57.8125], '/100/3.pth': [27.734375, 43.359375, 37.109375, 64.0625], '/100/4.pth': [28.90625, 45.3125, 39.0625, 63.671875], '/100/5.pth': [32.8125, 54.6875, 41.40625, 67.96875], '/100/6.pth': [32.8125, 52.34375, 44.921875, 67.578125], '/100/7.pth': [35.546875, 54.296875, 44.140625, 67.578125], '/100/8.pth': [40.625, 58.59375, 49.21875, 68.359375], '/100/9.pth': [38.28125, 57.8125, 48.828125, 68.75], '/100/10.pth': [39.84375, 60.15625, 46.09375, 69.53125], '/100/11.pth': [37.890625, 58.984375, 48.828125, 70.703125], '/100/12.pth': [46.875, 61.328125, 46.09375, 69.53125], '/100/13.pth': [42.1875, 62.5, 47.65625, 71.875], '/100/14.pth': [42.1875, 61.328125, 44.140625, 69.140625], '/100/15.pth': [41.40625, 60.9375, 44.140625, 68.75]}\n"
     ]
    }
   ],
   "source": [
    "filename = \"/home/aritra/project/quatLT23/6_pruning/acc_RN18_real_prunes_trial2.txt\"  # Replace with the name of your file\n",
    "my_dict = {}\n",
    "\n",
    "with open(filename, \"r\") as f:\n",
    "    i = 0\n",
    "    for line in f:\n",
    "        if i == 0: \n",
    "            i += 1\n",
    "            continue\n",
    "        items = line.strip().split(\" \")\n",
    "        key = items[0]\n",
    "        values = [float(val) for val in items[1:]]\n",
    "        my_dict[key] = values\n",
    "\n",
    "print(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 6, 8, 10, 13, 16, 20, 25, 32, 50, 64, 80, 100]\n",
      "{4: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 6: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 8: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 10: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 13: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 16: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 20: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 25: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 32: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 50: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 64: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 80: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625], 100: [10.546875, 19.921875, 27.734375, 28.90625, 32.8125, 32.8125, 35.546875, 40.625, 38.28125, 39.84375, 37.890625, 46.875, 42.1875, 42.1875, 41.40625]}\n",
      "{4: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 6: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 8: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 10: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 13: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 16: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 20: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 25: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 32: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 50: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 64: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 80: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625], 100: [19.921875, 31.25, 37.109375, 39.0625, 41.40625, 44.921875, 44.140625, 49.21875, 48.828125, 46.09375, 48.828125, 46.09375, 47.65625, 44.140625, 44.140625]}\n",
      "{4: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 6: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 8: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 10: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 13: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 16: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 20: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 25: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 32: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 50: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 64: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 80: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375], 100: [26.953125, 34.765625, 43.359375, 45.3125, 54.6875, 52.34375, 54.296875, 58.59375, 57.8125, 60.15625, 58.984375, 61.328125, 62.5, 61.328125, 60.9375]}\n",
      "{4: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 6: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 8: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 10: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 13: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 16: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 20: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 25: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 32: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 50: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 64: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 80: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75], 100: [39.0625, 57.8125, 64.0625, 63.671875, 67.96875, 67.578125, 67.578125, 68.359375, 68.75, 69.53125, 70.703125, 69.53125, 71.875, 69.140625, 68.75]}\n"
     ]
    }
   ],
   "source": [
    "train_acc = {}\n",
    "test_acc = {}\n",
    "train_acc_top5 = {}\n",
    "test_acc_top5 = {}\n",
    "prune_ratios = []\n",
    "for key in my_dict:\n",
    "    prune_ratios.append(int(key.split(\"/\")[-2])) if int(key.split(\"/\")[-2]) not in prune_ratios else prune_ratios\n",
    "\n",
    "print(prune_ratios)\n",
    "\n",
    "for key in my_dict:\n",
    "    prune_ratio = int(key.split(\"/\")[-2])\n",
    "    if prune_ratio not in train_acc:\n",
    "        train_acc[prune_ratio] = [my_dict[key][0]]\n",
    "        test_acc[prune_ratio] = [my_dict[key][2]]\n",
    "        train_acc_top5[prune_ratio] = [my_dict[key][1]]\n",
    "        test_acc_top5[prune_ratio] = [my_dict[key][3]]\n",
    "    else:\n",
    "        train_acc[prune_ratio].append(my_dict[key][0])\n",
    "        test_acc[prune_ratio].append(my_dict[key][2])\n",
    "        train_acc_top5[prune_ratio].append(my_dict[key][1])\n",
    "        test_acc_top5[prune_ratio].append(my_dict[key][3])\n",
    "\n",
    "# train_acc = [train_acc[key] for key in train_acc]\n",
    "# test_acc = [test_acc[key] for key in test_acc]\n",
    "# train_acc_top5 = [train_acc_top5[key] for key in train_acc_top5]\n",
    "# test_acc_top5 = [test_acc_top5[key] for key in test_acc_top5]\n",
    "        \n",
    "print(train_acc)\n",
    "print(test_acc)\n",
    "print(train_acc_top5)\n",
    "print(test_acc_top5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# individual train_acc plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(train_acc[prune_ratio], label=f\"train_acc_{prune_ratio}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy(%)\")\n",
    "    plt.title(f\"Train Accuracy vs Epochs for {prune_ratio}%\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/train_acc_{prune_ratio}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# individual test_acc plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(test_acc[prune_ratio], label=f\"test_acc_{prune_ratio}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy(%)\")\n",
    "    plt.title(f\"Test Accuracy vs Epochs for {prune_ratio}%\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/test_acc_{prune_ratio}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# individual train_acc_top5 plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(train_acc_top5[prune_ratio], label=f\"train_acc_top5_{prune_ratio}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy(%)\")\n",
    "    plt.title(f\"Train Accuracy Top5 vs Epochs for {prune_ratio}%\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/train_acc_top5_{prune_ratio}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# individual test_acc_top5 plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(test_acc_top5[prune_ratio], label=f\"test_acc_top5_{prune_ratio}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy(%)\")\n",
    "    plt.title(f\"Test Accuracy Top5 vs Epochs for {prune_ratio}%\")\n",
    "    plt.legend()\n",
    "    plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/test_acc_top5_{prune_ratio}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combined train_acc plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(train_acc[prune_ratio], label=f\"{prune_ratio}% w_left\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Train Accuracy vs Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/train_acc_combined.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combined test_acc plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(test_acc[prune_ratio], label=f\"{prune_ratio}% w_left\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Test Accuracy vs Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/test_acc_combined.png\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combined train_acc_top5 plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(train_acc_top5[prune_ratio], label=f\"{prune_ratio}% w_left\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Train Accuracy Top5 vs Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/train_acc_top5_combined.png\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combined test_acc_top5 plots\n",
    "for prune_ratio in prune_ratios:\n",
    "    plt.plot(test_acc_top5[prune_ratio], label=f\"{prune_ratio}% w_left\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Test Accuracy Top5 vs Epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/test_acc_top5_combined.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final train_acc plot for prunes\n",
    "final_train_acc = [train_acc[prune_ratio][-1] for prune_ratio in prune_ratios]\n",
    "plt.plot(prune_ratios, final_train_acc)\n",
    "plt.xlabel(\"Prune Ratio(%)\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Final Train Accuracy vs Prune Ratio\")\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/final_train_acc.png\")\n",
    "plt.clf()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test_acc plot for prunes\n",
    "final_test_acc = [test_acc[prune_ratio][-1] for prune_ratio in prune_ratios]\n",
    "plt.plot(prune_ratios, final_test_acc)\n",
    "plt.xlabel(\"Prune Ratio(%)\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Final Test Accuracy vs Prune Ratio\")\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/final_test_acc.png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final train_acc_top5 plot for prunes\n",
    "final_train_acc_top5 = [train_acc_top5[prune_ratio][-1] for prune_ratio in prune_ratios]\n",
    "plt.plot(prune_ratios, final_train_acc_top5)\n",
    "plt.xlabel(\"Prune Ratio(%)\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Final Train Accuracy Top5 vs Prune Ratio\")\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/final_train_acc_top5.png\")\n",
    "plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# final test_acc_top5 plot for prunes\n",
    "final_test_acc_top5 = [test_acc_top5[prune_ratio][-1] for prune_ratio in prune_ratios]\n",
    "plt.plot(prune_ratios, final_test_acc_top5)\n",
    "plt.xlabel(\"Prune Ratio(%)\")\n",
    "plt.ylabel(\"Accuracy(%)\")\n",
    "plt.title(f\"Final Test Accuracy Top5 vs Prune Ratio\")\n",
    "plt.savefig(f\"/home/aritra/project/quatLT23/6_pruning/saved_figs/RN_158_real_prunes/final_test_acc_top5.png\")\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
