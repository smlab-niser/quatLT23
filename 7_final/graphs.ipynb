{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.training import train_accuracy\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "from tqdm import tqdm, trange\n",
    "from data_loaders.imagenet import Train, Val\n",
    "import numpy as np\n",
    "from utils.pruning import get_prune_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rule(x):\n",
    "    a = x[10:-4]\n",
    "    try: return int(a)\n",
    "    except: return 0\n",
    "base_dir = \"saved_models/RN18_64_2\"\n",
    "all_models = listdir(base_dir)\n",
    "real_models = sorted([m for m in all_models if m.startswith(\"real\")], key = rule)\n",
    "quat_models = sorted([m for m in all_models if m.startswith(\"quat\")], key = rule)\n",
    "print(f\"{real_models = }\\n{quat_models = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator = torch.utils.data.DataLoader(Train(), batch_size=256, num_workers=4)\n",
    "validation_generator = torch.utils.data.DataLoader(Val(), batch_size=1024, num_workers=4)\n",
    "GPU = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_prune_percentage(torch.load(f\"{base_dir}/{real_models[0]}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_train_accs = []\n",
    "real_test_accs = []\n",
    "real_prune_percs = []\n",
    "for model_name in tqdm(real_models, desc=\"Real models\", unit=\"model\"):\n",
    "    model = torch.load(f\"{base_dir}/{model_name}\")\n",
    "    real_prune_percs.append(get_prune_percentage(model)*100)\n",
    "    # real_train_accs.append(train_accuracy(model, training_generator, GPU, 100))\n",
    "    real_test_accs.append(train_accuracy(model, validation_generator, GPU))\n",
    "\n",
    "# quat_train_accs = []\n",
    "quat_test_accs = []\n",
    "quat_prune_percs = []\n",
    "for model_name in tqdm(quat_models, desc=\"Quat models\", unit=\"model\"):\n",
    "    model = torch.load(f\"{base_dir}/{model_name}\")\n",
    "    quat_prune_percs.append(get_prune_percentage(model)*25)\n",
    "    # quat_train_accs.append(train_accuracy(model, training_generator, GPU, 100))\n",
    "    quat_test_accs.append(train_accuracy(model, validation_generator, GPU))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(real_prune_percs[:-1], real_test_accs[:-1], label=\"Real test acc\")\n",
    "plt.plot(quat_prune_percs[:-1], quat_test_accs[:-1], label=\"Quat test acc\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Prune percentage\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().invert_xaxis()\n",
    "# plt.xticks([0.25, 1, 5,  25, 100], [\"0.25%\", \"1%\", \"5%\", \"25%\", \"100%\"])\n",
    "plt.xticks([0.39, 1.56, 6.25,  25, 100], [\"0.39%\", \"1.56%\", \"6.25%\", \"25%\", \"100%\"])\n",
    "plt.ylim(10, 36)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://arxiv.org/pdf/2301.04623.pdf\n",
    "# https://openreview.net/pdf?id=K398CuAKVKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from models.resnet_real import ResNet18 as Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "\ttransforms.RandomCrop(32, padding=4),\n",
    "\ttransforms.RandomHorizontalFlip(),\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "\ttransforms.ToTensor(),\n",
    "\ttransforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(1, 4, 32, 32).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = torchvision.datasets.CIFAR100(root='/home/aritra/project/quatLT23/9_cifar100_RN18/cifar100', train=True, download=True, transform=transform_train)\n",
    "training_generator = torch.utils.data.DataLoader(trainset, batch_size=100, shuffle=True, drop_last=True)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='/home/aritra/project/quatLT23/9_cifar100_RN18/cifar100', train=False, download=True, transform=transform_test)\n",
    "validation_generator = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(3, 100).to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = next(iter(training_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 32, 32])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = torch.tensor(\n",
    "            [\n",
    "                [1, 0, 0, 0.299],\n",
    "                [0, 1, 0, 0.587],\n",
    "                [0, 0, 1, 0.144]\n",
    "            ]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x = batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 32, 32, 3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x.permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 4, 32, 32])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(np.dot(batch_x.numpy().transpose(0, 2, 3, 1), mat).transpose(0, 3, 1, 2)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:04<00:00, 102.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.900058269500732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "for batch_x, batch_y in tqdm(training_generator):\n",
    "    # print(batch_x.shape, batch_y.shape)\n",
    "    # break\n",
    "    \n",
    "    model(batch_x.to(\"cuda:0\"))\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_x = torch.Tensor(np.dot(batch_x.numpy().transpose(0, 2, 3, 1), mat).transpose(0, 3, 1, 2)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 32, 32)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x = np.random.randn(3, 32, 32)\n",
    "batch_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 4)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(batch_x.transpose(1, 2, 0), mat).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
